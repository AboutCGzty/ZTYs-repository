# 基于图像的照明

[TOC]

------

## 一、概述

现实中的间接光是由无数根在物体之间近乎无数次弹射的光线组成的，想要实时并且准确的计算这些光线需要非常庞大的运算量，会造成严重的性能消耗。这样的实时运算对于实时渲染领域的游戏是不现实的，尤其是移动端游戏。

所以就诞生了一种利用图像（环境贴图）来近似模拟间接光照的方法，称之为“基于图像的照明（Image based lighting，简称“IBL”）”。

具体分为以下两个部分：

（1）环境贴图是如何生成与使用的。

（2）基于环境贴图的照明是如何实现的。

## 二、环境贴图

### 2.1、什么是环境贴图

首先，环境贴图的本质就是一张“立方体贴图（Cubemap）”或“全景图（Panorama）”。

其原理很容易被理解，在场景的某个坐标点（如果没有特定坐标，默认为世界中心），分别在【前、后、左、右、上、下】六个方向上放置六个摄像机去捕获这六个方向向上的图像。最后将这六张图像在组合到一起，存储在一张纹理当中。引擎会根据纹理的的模式自动计算成立方体贴图的样式。如下图所示：

| ![img](3、基于图像的照明.assets/1690365661603-29c7cc50-4f30-41fb-8317-40a53cb95ba5.png) | <img src="3、基于图像的照明.assets/1690528964611-c3c2af8d-d55b-4f8d-879d-39b26d037595.png" alt="img" style="zoom: 80%;" /> |
| :----------------------------------------------------------: | :----------------------------------------------------------: |

常见的环境贴图有很多方式呈现，如下图所示：

| ![img](3、基于图像的照明.assets/1690472160358-9e272c8c-219b-49c4-a386-6b42cf49d9ff.jpeg) | <img src="3、基于图像的照明.assets/1690472187617-65443011-6f9d-4382-8aef-64a4d0cf45ea.png" alt="img" style="zoom:80%;" /> |
| :----------------------------------------------------------: | :----------------------------------------------------------: |

上图左侧为一张“立方体贴图（Cubemap）”，右侧为一张“全景图（Panorama）”。

### 2.2、如何生成环境贴图

生成环境贴图有多种方式，比如：

（1）使用“Unity”的“Reflection Probe”烘焙。

（2）编写脚本工具生成：

```c#
using UnityEngine;
using System.Collections;
using System.Collections.Generic;
using UnityEditor;
using System.IO;
using UnityEngine.Rendering;


public class RenderCubemap : EditorWindow
{
    public enum GenMode
    {
        SingleCubemap = 0,
        SixTextures
    }

    private static string[] _names = new string[] { "16", "32", "64", "128", "256", "512", "1024", "2048" };
    private static int[] _sizes = new int[] { 16, 32, 64, 128, 256, 512, 1024, 2048 };

    private static Vector3[] _cameraAngles = new Vector3[] {
        new Vector3(0, 90, 0), new Vector3(0, -90, 0),
        new Vector3(-90, 0, 0), new Vector3(90, 0, 0),
        new Vector3(0, 0, 0), new Vector3(0, 180, 0),
    };

    private static string[] _filePostfixs = new string[] {
        "_Left", "_Right", "_Top", "_Bottom", "_Front", "_Back"
    };

    private GenMode _genMode;
    private int _selectedSize = 1024;
    private int _lastSelectedSize;
    private RenderTexture[] _rtexs;
    private Texture2D[] _colorTexs;
    private Transform _center;
    [SerializeField]
    private LayerMask _layerMask = -1;
    SerializedObject serializedObject;

    void OnEnable()
    {
        titleContent = new GUIContent("RenderCubemap");
        serializedObject = new UnityEditor.SerializedObject(this);
    }

    void OnDestroy()
    {
        DestroyResources();
    }

    void CreateResources()
    {
        _rtexs = new RenderTexture[6];
        for (int i = 0; i < 6; i++)
        {
            _rtexs[i] = new RenderTexture(_selectedSize, _selectedSize, 24);
            _rtexs[i].hideFlags = HideFlags.HideAndDontSave;
        }

        _colorTexs = new Texture2D[6];
        for (int i = 0; i < 6; i++)
            _colorTexs[i] = new Texture2D(_selectedSize, _selectedSize, TextureFormat.RGB24, false);
    }

    void DestroyResources()
    {
        if (_rtexs != null)
        {
            for (int i = 0; i < 6; i++)
                DestroyImmediate(_rtexs[i]);
            _rtexs = null;
        }

        if (_colorTexs != null)
        {
            for (int i = 0; i < 6; i++)
            {
                DestroyImmediate(_colorTexs[i]);
            }
        }
    }

    void OnGUI()
    {

        GUILayout.Space(5);

        EditorGUI.BeginChangeCheck();
        _genMode = (GenMode)EditorGUILayout.EnumPopup("Mode", _genMode);
        _selectedSize = EditorGUILayout.IntPopup("Face Size", _selectedSize, _names, _sizes);
        _center = EditorGUILayout.ObjectField("Center", _center, typeof(Transform), true) as Transform;
        EditorGUILayout.PropertyField(serializedObject.FindProperty("_layerMask"));

        GUILayout.Space(15);

        bool hasError = false;
        Color oldContentColor = GUI.contentColor;
        GUI.contentColor = Color.red;
        if (_center == null)
        {
            GUILayout.Label("必须设置'Center'!");
            hasError = true;
        }
        Camera mainCam = Camera.main;
        if (mainCam == null)
        {
            GUI.contentColor = Color.red;
            GUILayout.Label("场景中必须有Main Camera!");
            hasError = true;
        }
        GUI.contentColor = oldContentColor;

        if (hasError)
        {
            return;
        }

        // _layerMask = EditorToolUtility.LayerMaskField("Culling Mask", _layerMask);
        GUILayout.Space(15);

        EditorGUILayout.BeginHorizontal();
        GUILayout.FlexibleSpace();
        if (GUILayout.Button("Bake", GUILayout.Width(100)))
        {
            if (_rtexs == null || _selectedSize != _lastSelectedSize)
            {
                DestroyResources();
                CreateResources();
                _lastSelectedSize = _selectedSize;
            }

            GameObject go = GameObject.Instantiate(mainCam.gameObject);
            go.name = "__CubemapCamera__";
            Camera cam = go.GetComponent<Camera>();
            cam.enabled = false;
            cam.backgroundColor = Camera.main.backgroundColor;
            cam.aspect = 1;
            cam.fieldOfView = 90;
            cam.cullingMask = _layerMask;

            go.transform.position = _center.position;

            RenderTexture oldRt = RenderTexture.active;
            for (int i = 0; i < 6; i++)
            {
                go.transform.localEulerAngles = _cameraAngles[i];

                RenderTexture.active = _rtexs[i];
                cam.targetTexture = _rtexs[i];
                cam.Render();

                _colorTexs[i].ReadPixels(new Rect(0, 0, _selectedSize, _selectedSize), 0, 0);
                _colorTexs[i].Apply();
            }

            RenderTexture.active = oldRt;
            DestroyImmediate(go);

            Texture2D tex = WriteAndImportTexture();
            if (tex != null)
                Debug.Log("渲染到环境贴图完成！", tex);
        }
        EditorGUILayout.EndHorizontal();
    }

    private Texture2D WriteAndImportTexture()
    {
        if (_genMode == GenMode.SingleCubemap)
        {
            string path = EditorUtility.SaveFilePanelInProject("Save Cubemap", "", "png", "Please enter a file name to save cubemap to");
            if (!string.IsNullOrEmpty(path))
            {
                Texture2D cubeTex = new Texture2D(_selectedSize * 4, _selectedSize * 3, TextureFormat.RGB24, false);

                Color[] colors = _colorTexs[0].GetPixels();
                cubeTex.SetPixels(_selectedSize * 2, _selectedSize, _selectedSize, _selectedSize, colors);
                colors = _colorTexs[1].GetPixels();
                cubeTex.SetPixels(0, _selectedSize, _selectedSize, _selectedSize, colors);
                colors = _colorTexs[2].GetPixels();
                cubeTex.SetPixels(_selectedSize, _selectedSize * 2, _selectedSize, _selectedSize, colors);
                colors = _colorTexs[3].GetPixels();
                cubeTex.SetPixels(_selectedSize, 0, _selectedSize, _selectedSize, colors);
                colors = _colorTexs[4].GetPixels();
                cubeTex.SetPixels(_selectedSize, _selectedSize, _selectedSize, _selectedSize, colors);
                colors = _colorTexs[5].GetPixels();
                cubeTex.SetPixels(_selectedSize * 3, _selectedSize, _selectedSize, _selectedSize, colors);

                cubeTex.Apply();
                byte[] bytes = cubeTex.EncodeToPNG();
                File.WriteAllBytes(path, bytes);
                AssetDatabase.ImportAsset(path);
                TextureImporter importer = AssetImporter.GetAtPath(path) as TextureImporter;
                importer.textureShape = TextureImporterShape.TextureCube;
                //importer.textureType = TextureImporterType.Cubemap;

                importer.generateCubemap = TextureImporterGenerateCubemap.AutoCubemap;
                importer.maxTextureSize = _selectedSize;
                AssetDatabase.ImportAsset(path, ImportAssetOptions.ForceUpdate);
                cubeTex = AssetDatabase.LoadAssetAtPath(path, typeof(Texture2D)) as Texture2D;

                return cubeTex;
            }
            return null;

        }
        else if (_genMode == GenMode.SixTextures)
        {
            string path = EditorUtility.SaveFilePanelInProject("Save Textures", "", "png", "Please enter a file name to save textures to");
            if (!string.IsNullOrEmpty(path))
            {
                //Material material = new Material(Shader.Find("Skybox/6 Sided"));
                //AssetDatabase.CreateAsset(material, path);

                string header = path.Substring(0, path.Length - 4);
                for (int i = 0; i < 6; i++)
                {
                    if (header.EndsWith(_filePostfixs[i]))
                    {
                        header = header.Substring(0, header.Length - _filePostfixs[i].Length);
                        break;
                    }
                }

                Texture2D[] newTextures = new Texture2D[6];
                for (int i = 0; i < 6; i++)
                {
                    string outPath = header + _filePostfixs[i] + ".png";

                    byte[] bytes = _colorTexs[i].EncodeToPNG();
                    File.WriteAllBytes(outPath, bytes);

                    AssetDatabase.ImportAsset(outPath);
                    TextureImporter importer = AssetImporter.GetAtPath(outPath) as TextureImporter;
                    importer.textureType = TextureImporterType.Default;
                    importer.wrapMode = TextureWrapMode.Clamp;
                    importer.maxTextureSize = _selectedSize;
                    AssetDatabase.ImportAsset(outPath, ImportAssetOptions.ForceUpdate);

                    newTextures[i] = AssetDatabase.LoadAssetAtPath(outPath, typeof(Texture2D)) as Texture2D;
                }

                return newTextures[0];
            }
        }

        return null;
    }

    [MenuItem("美术工具/生成立方体贴图", false, 5000)]
    private static void Init()
    {
        RenderCubemap editWindow = ScriptableObject.CreateInstance<RenderCubemap>();
        editWindow.Show();
    }
}
```

（3）使用第三方工具制作：

​	① HDR Shop：[ICT Vision & Graphics Lab (usc.edu)](https://vgl.ict.usc.edu/)

​	② HDR Light Studio：[HDR Light Studio - Make and edit image-based lighting in your 3D software (lightmap.co.uk)](https://www.lightmap.co.uk/)

​	③ cmftStudio：[cmftStudio - GUI counterpart of cmft - cross-platform open-source cubemap filtering - General Forums / Latest News - Blender Artists Community](https://blenderartists.org/t/cmftstudio-gui-counterpart-of-cmft-cross-platform-open-source-cubemap-filtering/636154?mobile_view=1)

## 三、Shader 中的环境贴图

### 3.1、反射向量

| <img src="3、基于图像的照明.assets/1690440976187-b393082d-61cf-462a-a1ad-faf53b563ceb.png" alt="img" style="zoom: 150%;" /> | <img src="3、基于图像的照明.assets/1690365585302-6d225018-ab7a-45e8-8bee-16e5db7db4db.png" alt="img"  /> | <img src="3、基于图像的照明.assets/1690365616846-69a34d96-f4dc-48c4-ab1e-c357749b0b93.png" alt="img" style="zoom:80%;" /> |
| :----------------------------------------------------------: | :----------------------------------------------------------: | :----------------------------------------------------------: |

如上图所示，在拿到相机视角的世界坐标位置后，使用内置函数“reflect()”计算得出“反射向量 R”。以下为代码示例：

```glsl
float3 cameraPosition = normalize(_WorldSpaceCameraPos.xyz - i.pos_world.xyz);
float3 reflecDir = normalize(reflect(-cameraPosition, i.normal_world));
```

### 3.2、采样环境贴图的方法

#### 3.2.1、方法一 - 立方体贴图

直接使用“反射向量 R”作为 UV 坐标使用内置函数“texCUBE()”采样“立方体贴图（Cubemap）”。

以下为代码示例：

```glsl
float3 cameraPosition = normalize(_WorldSpaceCameraPos.xyz - i.pos_world.xyz);
float3 reflecDir = normalize(reflect(-cameraPosition, i.normal_world));
float4 envCubemap = texCUBE(_textureCube, reflecDir);
```

效果如下所示：

<img src="3、基于图像的照明.assets/image-20240215020452844.png" alt="image-20240215020452844" style="zoom:50%;" />

但要注意一个问题，那就是通常场景中会使用一张具有 HDR 信息的纹理作为环境贴图，但在某些移动平台中不支持直接读取 HDR 信息。为了适应不同平台，因此需要对 HDR 信息先解码：

（1）声明一个以“_HDR”作为后缀的“float4”类型的变量，用于定义需要解码的 HDR 信息。

（2）使用内置函数“DecoadHDR()”来解码。

以下为代码示例：

```glsl
samplerCUBE _textureCube;
float4 _textureCube_HDR;

float4 frag(VertexOutput i) : SV_Target
{
  float3 cameraPosition = normalize(_WorldSpaceCameraPos.xyz - i.pos_world.xyz);
  float3 reflecDir = normalize(reflect(-cameraPosition, i.normal_world));
  float4 envCubemap = texCUBE(_textureCube, reflecDir);
  // 支持移动平台能获取到 HDR 信息
  float3 envCubemapHDR = DecodeHDR(envCubemap, _textureCube_HDR);
  return float4(envCubemapHDR, 1.0);
}
```

解码后的 HDR 信息可用于“Bloom 后处理”，如下对比图所示：

| <img src="3、基于图像的照明.assets/1690449192684-b270fb18-79ce-4794-b4fd-02525280d5b8.png" alt="img" style="zoom:50%;" /> | <img src="3、基于图像的照明.assets/1690449214771-01505baa-4907-452f-9fe6-9d1d25f05554.png" alt="img" style="zoom:50%;" /> |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

完整代码示例：

```glsl
Shader "IBL_Cubemap"
{
    Properties
    {
        [NoScaleOffset]_envCube ("Env Cube", Cube) = "white" { }
    }

    SubShader
    {
        Tags { "RenderType" = "Opaque" }

        Pass
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "UnityCG.cginc"

            struct VertexInput
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
            };

            struct VertexOutput
            {
                float4 pos : SV_POSITION;
                float3 pos_world : TEXCOORD0;
                float3 normal_world : TEXCOORD1;
            };

            VertexOutput vert(VertexInput v)
            {
                VertexOutput o;
                o.pos = UnityObjectToClipPos(v.vertex);
                o.pos_world = mul(unity_ObjectToWorld, v.vertex);
                o.normal_world = UnityObjectToWorldNormal(v.normal);
                return o;
            }

            float _envRotation;
            float4 _envCube_HDR;
            samplerCUBE _envCube;

            float4 frag(VertexOutput i) : SV_Target
            {
                float3 worldNormal = normalize(i.normal_world);
                float3 cameraPosition = normalize(_WorldSpaceCameraPos.xyz - i.pos_world.xyz);
                float3 reflecDir = normalize(reflect(-cameraPosition, worldNormal));
                float4 envCubemap = texCUBE(_envCube, reflecDir);
                float3 envCubemapHDR = DecodeHDR(envCubemap, _envCube_HDR);
                return float4(envCubemapHDR, 1.0);
            }
            ENDCG
        }
    }
}
```

#### 3.2.2、方法二 - 全景图

此方法通过修改“反射向量 R”作为环境贴图的坐标来采样“2D 全景图（Panorama）”。

将“反射向量 R”从三维转换至二维算法如下：

```glsl
float2 ReflectionDir2(float3 reflecDir)
{
  float latItude = acos(reflecDir.y);
  float longItude = atan2(reflecDir.z, reflecDir.x);
  float2 amount = float2(0.5 / UNITY_PI, 1.0 / UNITY_PI);
  float2 coordsSphere = float2(longItude, latItude);
  coordsSphere *= amount;
  float2 uv_Panorama = float2(0.5, 1.0) - coordsSphere;
  return uv_Panorama;
}
```

得到二维空间“反射向量 R”后，采样“2D 全景图（Panorama）”，代码示例如下：

```glsl
  float3 cameraPosition = normalize(_WorldSpaceCameraPos.xyz - i.pos_world.xyz);
  float3 reflecDir = normalize(reflect(-cameraPosition, i.normal_world));
  // 将“反射向量 R”从三维转换至二维算法
  float2 reflecDirPanorama = ReflectionDir2(reflecDir);
  // 采样 2D 全景图
  float4 envPanorama = texCUBE(_texture2D, reflecDirPanorama);
```

效果如下所示：

<img src="3、基于图像的照明.assets/image-20240215021420278.png" alt="image-20240215021420278" style="zoom: 50%;" />

完整代码示例：

```glsl
Shader "IBL_Panorama"
{
    Properties
    {
        [NoScaleOffset]_envPanorama ("Env Panorama", 2D) = "white" { }
    }

    SubShader
    {
        Tags { "RenderType" = "Opaque" }

        Pass
        {
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "UnityCG.cginc"

            struct VertexInput
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
            };

            struct VertexOutput
            {
                float4 pos : SV_POSITION;
                float3 pos_world : TEXCOORD0;
                float3 normal_world : TEXCOORD1;
            };

            VertexOutput vert(VertexInput v)
            {
                VertexOutput o;
                o.pos = UnityObjectToClipPos(v.vertex);
                o.pos_world = mul(unity_ObjectToWorld, v.vertex);
                o.normal_world = UnityObjectToWorldNormal(v.normal);
                return o;
            }

            float _rotationAngle;
            float4 _envPanorama_HDR;
            sampler2D _envPanorama;

            float2 ReflectionDir2(float3 reflecDir)
            {
                float latItude = acos(reflecDir.y);
                float longItude = atan2(reflecDir.z, reflecDir.x);
                float2 amount = float2(0.5 / UNITY_PI, 1.0 / UNITY_PI);
                float2 coordsSphere = float2(longItude, latItude);
                coordsSphere *= amount;
                float2 uv_Panorama = float2(0.5, 1.0) - coordsSphere;
                return uv_Panorama;
            }

            float4 frag(VertexOutput i) : SV_Target
            {
                float3 worldNormal = normalize(i.normal_world);
                float3 cameraPosition = normalize(_WorldSpaceCameraPos.xyz - i.pos_world.xyz);
                float3 reflecDir = normalize(reflect(-cameraPosition, worldNormal));
  			   // 将“反射向量 R”从三维转换至二维算法
                float2 panoramaUV = ReflectionDir2(reflecDir);
  			   // 采样 2D 全景图
                float4 envPanorama = tex2D(_envPanorama, panoramaUV);
                float3 envPanoramaHDR = DecodeHDR(envPanorama, _envPanorama_HDR);
                return float4(envPanoramaHDR, 1.0);
            }
            ENDCG
        }
    }
}
```

### 3.3、可旋转的反射向量

也可以对“反射向量 R”进行改进得到一个可以围绕“Y 轴”旋转的新“反射向量 R”。大致思路如下：

（1）使用以下“角度转弧度公式”计算出旋转角度：
$$
旋转角度 = 旋转数值 * UNITY_-PI / 180.0
$$
（2）构建一个以二位旋转矩阵，并使用矩阵乘法“mul()”用来修改“反射向量 R”的“xz”分量。

（3）最终对反射向量【R】的三个分量进行重组就得到了新的可以旋转的反射向量【R】。

具体算法示例如下所示：

```glsl
float3 RotationY(float angle, float3 reflecDir)
{
  // 角度转弧度公式
  float rotationAngle = angle * UNITY_PI / 180.0;
  // 构建二维旋转矩阵
  float2x2 m_Rotation = float2x2(cos(rotationAngle), -sin(rotationAngle), sin(rotationAngle), cos(rotationAngle));
  // 修改反射向量
  float2 rotationDir = mul(m_Rotation, reflecDir.xz);
  reflecDir = float3(rotationDir.x, reflecDir.y, rotationDir.y);
  return reflecDir;
}
```

效果预览：

<img src="3、基于图像的照明.assets/1690451178961-8736d863-8e6a-448d-88d7-386753390911.gif" alt="1690451178961-8736d863-8e6a-448d-88d7-386753390911" style="zoom:50%;" />

## 四、局限性与解决方案

### 4.1、局限性

使用“立方体贴图（Cubemap）”之类的方案会存在采样点误差的问题，如下图所示：

| <img src="3、基于图像的照明.assets/1690441489299-26ffc111-46e1-4f94-9edc-4116261447d4.png" alt="img" style="zoom: 150%;" /> | <img src="3、基于图像的照明.assets/1690511990428-a59c5ed7-21ee-4ff0-b307-70836e65fdff.png" alt="img" style="zoom: 80%;" /> |
| ------------------------------------------------------------ | ------------------------------------------------------------ |

上面左侧图的方法只根据反射方向来进行采样，而对于“点 P”与“点 origin”来说，二者的反射向量的方向及大小都一致。但从几何意义角度出发，这两个向量却相等，所以造成了最终采样点不明确的缺陷。从而最终导致上面右侧图中图像的错位、失真等问题。

这也是为什么“立方体贴图（Cubemap）”技术不适合用于平面模型进行反射的原因。

### 4.2、解决方案

为了解决“立方体贴图（Cubemap）”存在的误差问题，可以使用“Local Reflection”的改良方案。“Local Reflection”通过纠正“反射向量 R”并配合参数就可以达到准确的平面反射效果，如下图所示：

| ![img](3、基于图像的照明.assets/1690526146966-c4b508e1-325f-4fe5-ba0a-f1407267e48d.png) | ![img](3、基于图像的照明.assets/1690526173790-5b51983d-93c6-472f-8542-2b68e1307c4e.png) |
| :----------------------------------------------------------: | :----------------------------------------------------------: |

上图左侧是未使用“Local Reflection”的错误效果，右侧是使用了“Local Reflection”后的正确效果。并且，侧立面的反射也是可以被纠正的，如下图所示：

| ![img](3、基于图像的照明.assets/1690648619696-58fe11a8-0f43-46d1-a086-6ee93e95ef20.png) | ![img](3、基于图像的照明.assets/1690648651386-4a17790d-5d54-495f-8185-911c800ae7d0.png) |
| :----------------------------------------------------------: | :----------------------------------------------------------: |

以下为“Local Reflection”的示例代码：

```glsl
float3 LocalReflection(float3 reflecDir, float3 worldPosition, float3 boxSize, float3 boxCenter)
{
  float3 a = (-boxSize - worldPosition) / reflecDir;
  float3 b = (boxSize - worldPosition) / reflecDir;
  float3 c = max(a, b);
  float d = min(min(c.x, c.y), c.z);

  float3 finalReflectionDir = d * reflecDir + worldPosition + boxCenter;
  return normalize(finalReflectionDir);
}
```

完整示例代码：

```glsl
Shader "IBL_LocalReflection"
{
    Properties
    {
        [NoScaleOffset]_envCube ("Env Cube", Cube) = "white" { }
        [Toggle(LOCALREFLECTION)]_localReflection ("Local Reflection", float) = 0.0
        _envSize ("Env Size", vector) = (5.0, 5.0, 5.0, 0.0)
        _envCenter ("Env Center", vector) = (0.0, 0.0, 0.0, 0.0)
    }

    SubShader
    {
        Tags { "RenderType" = "Opaque" }

        Pass
        {
            Name "FORWARDLIT"
            CGPROGRAM
            #pragma vertex vert
            #pragma fragment frag
            #include "UnityCG.cginc"
            #pragma shader_feature_local LOCALREFLECTION

            struct VertexInput
            {
                float4 vertex : POSITION;
                float3 normal : NORMAL;
            };

            struct VertexOutput
            {
                float4 pos : SV_POSITION;
                float3 pos_world : TEXCOORD0;
                float3 normal_world : TEXCOORD1;
            };

            VertexOutput vert(VertexInput v)
            {
                VertexOutput o;
                o.pos = UnityObjectToClipPos(v.vertex);
                o.pos_world = mul(unity_ObjectToWorld, v.vertex);
                o.normal_world = UnityObjectToWorldNormal(v.normal);
                return o;
            }

            float4 _envCube_HDR, _envSize, _envCenter;
            samplerCUBE _envCube;

            float3 LocalReflection(float3 reflecDir, float3 worldPosition, float3 boxSize, float3 boxCenter)
            {
                float3 a = (-boxSize - worldPosition) / reflecDir;
                float3 b = (boxSize - worldPosition) / reflecDir;
                float3 c = max(a, b);
                float d = min(min(c.x, c.y), c.z);
                float3 finalReflectionDir = d * reflecDir + worldPosition + boxCenter;
                return normalize(finalReflectionDir);
            }

            float4 frag(VertexOutput i) : SV_Target
            {
                float3 worldNormal = normalize(i.normal_world);
                float3 cameraPosition = normalize(_WorldSpaceCameraPos.xyz - i.pos_world.xyz);
                float3 reflecDir = normalize(reflect(-cameraPosition, worldNormal));
                #ifdef LOCALREFLECTION
                    reflecDir = LocalReflection(reflecDir, i.pos_world.xyz, _envSize, _envCenter);
                #endif
                // Cubemap
                float4 envCubemap = texCUBE(_envCube, reflecDir);
                float3 envCubemapHDR = DecodeHDR(envCubemap, _envCube_HDR);

                return float4(envCubemapHDR, 1.0);
            }
            ENDCG
        }
    }
}
```
